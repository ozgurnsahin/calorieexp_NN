{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0041c992",
   "metadata": {},
   "source": [
    "Install and import necesseary libraries, frameworks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2158b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 21:28:38.959642: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-07 21:28:39.888005: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-07 21:28:40.472122: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746642521.588164    1488 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746642521.798804    1488 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746642523.854709    1488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746642523.854767    1488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746642523.854774    1488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746642523.854780    1488 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-07 21:28:44.018598: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332b6cc",
   "metadata": {},
   "source": [
    "Load train and test data as pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a04aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv',na_filter=False)\n",
    "test_df = pd.read_csv('test.csv',na_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25125507",
   "metadata": {},
   "source": [
    "Drop 'id' columns because it does not provide meaningful data to predict the calorie expenditure. Its being will cause faults when traning and testing the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa94fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns='id',inplace=True)\n",
    "test_df.drop(columns='id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df675fca",
   "metadata": {},
   "source": [
    "Processing data for model training looking for NaN values on the dataset and handling them, dropping unnecesseary columns, transform data and split data to test and train splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b83386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dataframe):\n",
    "    if dataframe.isna().sum().sum() > 0 or dataframe.isnull().sum().sum() > 0:\n",
    "        dataframe.dropna\n",
    "    \n",
    "    X = dataframe.drop(columns='Calories')\n",
    "    Y = dataframe['Calories']\n",
    "    \n",
    "    numeric_features = ['Age','Height','Weight','Heart_Rate','Body_Temp']\n",
    "    categorical_features = ['Sex']\n",
    "    \n",
    "    num_encoder = StandardScaler()\n",
    "    cat_encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers= [('num', num_encoder, numeric_features),('cat',cat_encoder,categorical_features)])\n",
    "    \n",
    "    X_precessed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_precessed, Y , test_size=0.25, random_state=42)\n",
    "    \n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24d2f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (562500, 6)\n",
      "X_test shape: (187500, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = process_data(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8be39d",
   "metadata": {},
   "source": [
    "Building Neural Network for regression traning using ReLu for activation function, optimized with adam optimizer and used a MSE for the loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ff90efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=[keras.metrics.MeanSquaredError(name=\"mean_squared_error\", dtype=None), \n",
    "                  keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None)\n",
    "                  ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e6e6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albatrosfirst/calorieexp_NN/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "E0000 00:00:1746617068.633150    1689 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1746617068.850269    1689 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,457</span> (13.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,457\u001b[0m (13.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,265</span> (12.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,265\u001b[0m (12.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160d96c",
   "metadata": {},
   "source": [
    "Defining train_model function this function accepts model and traning and test data splits, creates a callback object of keras EarlyStopping class restore to the best paramaters on while traning to acces the best trarning epochs. Configuring model trainig with train data splits, batch sizes and validation data and returning model and traning history of the epochs results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdabea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, x_test, y_train, y_test):\n",
    "    callback = keras.callbacks.EarlyStopping(\n",
    "        monitor='loss', \n",
    "        patience=5, \n",
    "        restore_best_weights=True\n",
    "        )\n",
    "    \n",
    "    traning = model.fit(x= x_train,\n",
    "              y= y_train,\n",
    "              epochs= 100,\n",
    "              callbacks= [callback],\n",
    "              batch_size= 64,\n",
    "              validation_data= (x_test, y_test),\n",
    "              )\n",
    "    \n",
    "    return model, traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a2e472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 9ms/step - loss: 217.6876 - mean_absolute_error: 10.7235 - mean_squared_error: 217.6876 - val_loss: 181.3868 - val_mean_absolute_error: 9.7507 - val_mean_squared_error: 181.3868\n",
      "Epoch 2/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 10ms/step - loss: 215.7873 - mean_absolute_error: 10.6510 - mean_squared_error: 215.7873 - val_loss: 182.0086 - val_mean_absolute_error: 9.8358 - val_mean_squared_error: 182.0086\n",
      "Epoch 3/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 10ms/step - loss: 214.4155 - mean_absolute_error: 10.6327 - mean_squared_error: 214.4155 - val_loss: 182.7892 - val_mean_absolute_error: 9.8464 - val_mean_squared_error: 182.7892\n",
      "Epoch 4/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 14ms/step - loss: 212.2582 - mean_absolute_error: 10.5865 - mean_squared_error: 212.2582 - val_loss: 182.5332 - val_mean_absolute_error: 9.8672 - val_mean_squared_error: 182.5332\n",
      "Epoch 5/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 16ms/step - loss: 210.3065 - mean_absolute_error: 10.5199 - mean_squared_error: 210.3065 - val_loss: 180.4147 - val_mean_absolute_error: 9.6869 - val_mean_squared_error: 180.4147\n",
      "Epoch 6/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 11ms/step - loss: 211.7108 - mean_absolute_error: 10.5620 - mean_squared_error: 211.7108 - val_loss: 182.2573 - val_mean_absolute_error: 9.8852 - val_mean_squared_error: 182.2573\n",
      "Epoch 7/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 11ms/step - loss: 211.6688 - mean_absolute_error: 10.5395 - mean_squared_error: 211.6688 - val_loss: 182.9235 - val_mean_absolute_error: 9.8059 - val_mean_squared_error: 182.9235\n",
      "Epoch 8/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 11ms/step - loss: 210.5685 - mean_absolute_error: 10.5191 - mean_squared_error: 210.5685 - val_loss: 181.8737 - val_mean_absolute_error: 9.8887 - val_mean_squared_error: 181.8737\n",
      "Epoch 9/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 11ms/step - loss: 210.0201 - mean_absolute_error: 10.4792 - mean_squared_error: 210.0201 - val_loss: 182.6487 - val_mean_absolute_error: 9.8848 - val_mean_squared_error: 182.6487\n",
      "Epoch 10/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 12ms/step - loss: 208.9655 - mean_absolute_error: 10.4719 - mean_squared_error: 208.9655 - val_loss: 184.7523 - val_mean_absolute_error: 10.1132 - val_mean_squared_error: 184.7523\n",
      "Epoch 11/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 12ms/step - loss: 207.5771 - mean_absolute_error: 10.4318 - mean_squared_error: 207.5771 - val_loss: 186.4602 - val_mean_absolute_error: 10.0938 - val_mean_squared_error: 186.4602\n",
      "Epoch 12/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 11ms/step - loss: 208.0512 - mean_absolute_error: 10.4201 - mean_squared_error: 208.0512 - val_loss: 182.4354 - val_mean_absolute_error: 9.8747 - val_mean_squared_error: 182.4354\n",
      "Epoch 13/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 11ms/step - loss: 207.3380 - mean_absolute_error: 10.3936 - mean_squared_error: 207.3380 - val_loss: 185.4031 - val_mean_absolute_error: 10.0299 - val_mean_squared_error: 185.4031\n",
      "Epoch 14/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 15ms/step - loss: 206.2420 - mean_absolute_error: 10.3765 - mean_squared_error: 206.2420 - val_loss: 193.2737 - val_mean_absolute_error: 10.3228 - val_mean_squared_error: 193.2737\n",
      "Epoch 15/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 12ms/step - loss: 207.0607 - mean_absolute_error: 10.3815 - mean_squared_error: 207.0607 - val_loss: 182.6866 - val_mean_absolute_error: 9.8580 - val_mean_squared_error: 182.6866\n",
      "Epoch 16/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 10ms/step - loss: 206.2309 - mean_absolute_error: 10.3636 - mean_squared_error: 206.2309 - val_loss: 182.2212 - val_mean_absolute_error: 9.9143 - val_mean_squared_error: 182.2212\n",
      "Epoch 17/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 13ms/step - loss: 207.4630 - mean_absolute_error: 10.3722 - mean_squared_error: 207.4630 - val_loss: 186.0727 - val_mean_absolute_error: 10.1532 - val_mean_squared_error: 186.0727\n",
      "Epoch 18/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 206.0314 - mean_absolute_error: 10.3385 - mean_squared_error: 206.0314 - val_loss: 184.0897 - val_mean_absolute_error: 10.0102 - val_mean_squared_error: 184.0897\n",
      "Epoch 19/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9ms/step - loss: 204.4765 - mean_absolute_error: 10.3108 - mean_squared_error: 204.4765 - val_loss: 186.3336 - val_mean_absolute_error: 10.1673 - val_mean_squared_error: 186.3336\n",
      "Epoch 20/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 205.3799 - mean_absolute_error: 10.3228 - mean_squared_error: 205.3799 - val_loss: 182.3136 - val_mean_absolute_error: 9.8300 - val_mean_squared_error: 182.3136\n",
      "Epoch 21/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9ms/step - loss: 204.0119 - mean_absolute_error: 10.3115 - mean_squared_error: 204.0119 - val_loss: 181.6956 - val_mean_absolute_error: 9.8492 - val_mean_squared_error: 181.6956\n",
      "Epoch 22/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 9ms/step - loss: 205.5733 - mean_absolute_error: 10.3367 - mean_squared_error: 205.5733 - val_loss: 184.1029 - val_mean_absolute_error: 9.8299 - val_mean_squared_error: 184.1029\n",
      "Epoch 23/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 9ms/step - loss: 204.0072 - mean_absolute_error: 10.3004 - mean_squared_error: 204.0072 - val_loss: 189.3995 - val_mean_absolute_error: 10.1428 - val_mean_squared_error: 189.3995\n",
      "Epoch 24/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 9ms/step - loss: 205.2004 - mean_absolute_error: 10.3193 - mean_squared_error: 205.2004 - val_loss: 192.1601 - val_mean_absolute_error: 10.4934 - val_mean_squared_error: 192.1601\n",
      "Epoch 25/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 9ms/step - loss: 204.3893 - mean_absolute_error: 10.3078 - mean_squared_error: 204.3893 - val_loss: 186.7911 - val_mean_absolute_error: 10.1934 - val_mean_squared_error: 186.7911\n",
      "Epoch 26/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 11ms/step - loss: 203.2895 - mean_absolute_error: 10.2674 - mean_squared_error: 203.2895 - val_loss: 190.6761 - val_mean_absolute_error: 10.3500 - val_mean_squared_error: 190.6761\n",
      "Epoch 27/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 11ms/step - loss: 203.7938 - mean_absolute_error: 10.2813 - mean_squared_error: 203.7938 - val_loss: 191.3964 - val_mean_absolute_error: 10.3850 - val_mean_squared_error: 191.3964\n",
      "Epoch 28/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 10ms/step - loss: 203.2870 - mean_absolute_error: 10.2745 - mean_squared_error: 203.2870 - val_loss: 183.8878 - val_mean_absolute_error: 10.0068 - val_mean_squared_error: 183.8878\n",
      "Epoch 29/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 11ms/step - loss: 203.0465 - mean_absolute_error: 10.2602 - mean_squared_error: 203.0465 - val_loss: 188.4962 - val_mean_absolute_error: 10.3195 - val_mean_squared_error: 188.4962\n",
      "Epoch 30/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10ms/step - loss: 204.0533 - mean_absolute_error: 10.2696 - mean_squared_error: 204.0533 - val_loss: 193.6562 - val_mean_absolute_error: 10.4779 - val_mean_squared_error: 193.6562\n",
      "Epoch 31/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 9ms/step - loss: 203.5551 - mean_absolute_error: 10.2695 - mean_squared_error: 203.5551 - val_loss: 198.9058 - val_mean_absolute_error: 10.6972 - val_mean_squared_error: 198.9058\n",
      "Epoch 32/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 9ms/step - loss: 203.6579 - mean_absolute_error: 10.2689 - mean_squared_error: 203.6579 - val_loss: 187.6053 - val_mean_absolute_error: 10.2285 - val_mean_squared_error: 187.6053\n",
      "Epoch 33/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 202.6376 - mean_absolute_error: 10.2536 - mean_squared_error: 202.6376 - val_loss: 189.2008 - val_mean_absolute_error: 10.2197 - val_mean_squared_error: 189.2008\n",
      "Epoch 34/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 201.9001 - mean_absolute_error: 10.2340 - mean_squared_error: 201.9001 - val_loss: 188.7635 - val_mean_absolute_error: 10.2393 - val_mean_squared_error: 188.7635\n",
      "Epoch 35/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 203.4358 - mean_absolute_error: 10.2748 - mean_squared_error: 203.4358 - val_loss: 191.6098 - val_mean_absolute_error: 10.3603 - val_mean_squared_error: 191.6098\n",
      "Epoch 36/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 203.3289 - mean_absolute_error: 10.2699 - mean_squared_error: 203.3289 - val_loss: 199.0792 - val_mean_absolute_error: 10.5696 - val_mean_squared_error: 199.0792\n",
      "Epoch 37/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 202.1217 - mean_absolute_error: 10.2459 - mean_squared_error: 202.1217 - val_loss: 195.1258 - val_mean_absolute_error: 10.3403 - val_mean_squared_error: 195.1258\n",
      "Epoch 38/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 10ms/step - loss: 203.0148 - mean_absolute_error: 10.2436 - mean_squared_error: 203.0148 - val_loss: 186.4935 - val_mean_absolute_error: 10.1840 - val_mean_squared_error: 186.4935\n",
      "Epoch 39/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10ms/step - loss: 203.3571 - mean_absolute_error: 10.2482 - mean_squared_error: 203.3571 - val_loss: 187.6937 - val_mean_absolute_error: 10.0275 - val_mean_squared_error: 187.6937\n",
      "Epoch 40/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 10ms/step - loss: 201.7017 - mean_absolute_error: 10.2214 - mean_squared_error: 201.7017 - val_loss: 192.6360 - val_mean_absolute_error: 10.5275 - val_mean_squared_error: 192.6360\n",
      "Epoch 41/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 10ms/step - loss: 200.6322 - mean_absolute_error: 10.1990 - mean_squared_error: 200.6322 - val_loss: 189.7305 - val_mean_absolute_error: 10.4139 - val_mean_squared_error: 189.7305\n",
      "Epoch 42/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 11ms/step - loss: 203.5952 - mean_absolute_error: 10.2531 - mean_squared_error: 203.5952 - val_loss: 191.9933 - val_mean_absolute_error: 10.5083 - val_mean_squared_error: 191.9933\n",
      "Epoch 43/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 10ms/step - loss: 201.8735 - mean_absolute_error: 10.2376 - mean_squared_error: 201.8735 - val_loss: 190.4827 - val_mean_absolute_error: 10.3405 - val_mean_squared_error: 190.4827\n",
      "Epoch 44/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10ms/step - loss: 201.7045 - mean_absolute_error: 10.2096 - mean_squared_error: 201.7045 - val_loss: 196.4598 - val_mean_absolute_error: 10.7346 - val_mean_squared_error: 196.4598\n",
      "Epoch 45/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 10ms/step - loss: 201.3076 - mean_absolute_error: 10.2154 - mean_squared_error: 201.3076 - val_loss: 195.4574 - val_mean_absolute_error: 10.5386 - val_mean_squared_error: 195.4574\n",
      "Epoch 46/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 10ms/step - loss: 202.8578 - mean_absolute_error: 10.2409 - mean_squared_error: 202.8578 - val_loss: 196.0042 - val_mean_absolute_error: 10.5060 - val_mean_squared_error: 196.0042\n",
      "Epoch 47/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 201.4056 - mean_absolute_error: 10.2148 - mean_squared_error: 201.4056 - val_loss: 193.6749 - val_mean_absolute_error: 10.4076 - val_mean_squared_error: 193.6749\n",
      "Epoch 48/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 9ms/step - loss: 201.1080 - mean_absolute_error: 10.1917 - mean_squared_error: 201.1080 - val_loss: 202.5414 - val_mean_absolute_error: 10.8333 - val_mean_squared_error: 202.5414\n",
      "Epoch 49/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 10ms/step - loss: 201.0285 - mean_absolute_error: 10.1998 - mean_squared_error: 201.0285 - val_loss: 205.3424 - val_mean_absolute_error: 11.0301 - val_mean_squared_error: 205.3424\n",
      "Epoch 50/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 10ms/step - loss: 201.5014 - mean_absolute_error: 10.2184 - mean_squared_error: 201.5014 - val_loss: 197.9727 - val_mean_absolute_error: 10.6827 - val_mean_squared_error: 197.9727\n",
      "Epoch 51/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 201.2412 - mean_absolute_error: 10.2101 - mean_squared_error: 201.2412 - val_loss: 195.5737 - val_mean_absolute_error: 10.5309 - val_mean_squared_error: 195.5737\n",
      "Epoch 52/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 10ms/step - loss: 202.6408 - mean_absolute_error: 10.2338 - mean_squared_error: 202.6408 - val_loss: 192.8517 - val_mean_absolute_error: 10.5037 - val_mean_squared_error: 192.8517\n",
      "Epoch 53/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10ms/step - loss: 202.5788 - mean_absolute_error: 10.2412 - mean_squared_error: 202.5788 - val_loss: 197.3540 - val_mean_absolute_error: 10.7929 - val_mean_squared_error: 197.3540\n",
      "Epoch 54/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 9ms/step - loss: 201.0194 - mean_absolute_error: 10.2069 - mean_squared_error: 201.0194 - val_loss: 195.7968 - val_mean_absolute_error: 10.3821 - val_mean_squared_error: 195.7968\n",
      "Epoch 55/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 10ms/step - loss: 201.0502 - mean_absolute_error: 10.2110 - mean_squared_error: 201.0502 - val_loss: 190.3580 - val_mean_absolute_error: 10.3225 - val_mean_squared_error: 190.3580\n",
      "Epoch 56/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 201.8083 - mean_absolute_error: 10.1947 - mean_squared_error: 201.8083 - val_loss: 198.6140 - val_mean_absolute_error: 10.7747 - val_mean_squared_error: 198.6140\n",
      "Epoch 57/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 9ms/step - loss: 201.6975 - mean_absolute_error: 10.2218 - mean_squared_error: 201.6975 - val_loss: 188.1426 - val_mean_absolute_error: 10.2008 - val_mean_squared_error: 188.1426\n",
      "Epoch 58/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9ms/step - loss: 200.9083 - mean_absolute_error: 10.2085 - mean_squared_error: 200.9083 - val_loss: 196.8513 - val_mean_absolute_error: 10.5048 - val_mean_squared_error: 196.8513\n",
      "Epoch 59/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 9ms/step - loss: 200.5030 - mean_absolute_error: 10.2011 - mean_squared_error: 200.5030 - val_loss: 189.9700 - val_mean_absolute_error: 10.1030 - val_mean_squared_error: 189.9700\n",
      "Epoch 60/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9ms/step - loss: 200.6743 - mean_absolute_error: 10.1947 - mean_squared_error: 200.6743 - val_loss: 196.0639 - val_mean_absolute_error: 10.5480 - val_mean_squared_error: 196.0639\n",
      "Epoch 61/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 9ms/step - loss: 201.2135 - mean_absolute_error: 10.1999 - mean_squared_error: 201.2135 - val_loss: 200.6889 - val_mean_absolute_error: 10.5606 - val_mean_squared_error: 200.6889\n",
      "Epoch 62/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 9ms/step - loss: 201.3867 - mean_absolute_error: 10.2011 - mean_squared_error: 201.3867 - val_loss: 192.5233 - val_mean_absolute_error: 10.4339 - val_mean_squared_error: 192.5233\n",
      "Epoch 63/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 9ms/step - loss: 199.4860 - mean_absolute_error: 10.1768 - mean_squared_error: 199.4860 - val_loss: 191.3652 - val_mean_absolute_error: 10.4246 - val_mean_squared_error: 191.3652\n",
      "Epoch 64/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 9ms/step - loss: 200.9129 - mean_absolute_error: 10.1840 - mean_squared_error: 200.9129 - val_loss: 187.2509 - val_mean_absolute_error: 10.1125 - val_mean_squared_error: 187.2509\n",
      "Epoch 65/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 9ms/step - loss: 200.7396 - mean_absolute_error: 10.1806 - mean_squared_error: 200.7396 - val_loss: 203.0468 - val_mean_absolute_error: 10.8361 - val_mean_squared_error: 203.0468\n",
      "Epoch 66/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 9ms/step - loss: 201.0554 - mean_absolute_error: 10.1967 - mean_squared_error: 201.0554 - val_loss: 205.2677 - val_mean_absolute_error: 10.7668 - val_mean_squared_error: 205.2677\n",
      "Epoch 67/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9ms/step - loss: 200.7033 - mean_absolute_error: 10.1855 - mean_squared_error: 200.7033 - val_loss: 197.3260 - val_mean_absolute_error: 10.6265 - val_mean_squared_error: 197.3260\n",
      "Epoch 68/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 9ms/step - loss: 200.5744 - mean_absolute_error: 10.1895 - mean_squared_error: 200.5744 - val_loss: 194.9704 - val_mean_absolute_error: 10.4724 - val_mean_squared_error: 194.9704\n",
      "Epoch 69/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10ms/step - loss: 200.3509 - mean_absolute_error: 10.1759 - mean_squared_error: 200.3509 - val_loss: 195.0425 - val_mean_absolute_error: 10.4762 - val_mean_squared_error: 195.0425\n",
      "Epoch 70/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 9ms/step - loss: 199.5968 - mean_absolute_error: 10.1647 - mean_squared_error: 199.5968 - val_loss: 192.7853 - val_mean_absolute_error: 10.4600 - val_mean_squared_error: 192.7853\n",
      "Epoch 71/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 9ms/step - loss: 200.3271 - mean_absolute_error: 10.1901 - mean_squared_error: 200.3271 - val_loss: 197.7043 - val_mean_absolute_error: 10.4827 - val_mean_squared_error: 197.7043\n",
      "Epoch 72/100\n",
      "\u001b[1m8790/8790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 9ms/step - loss: 201.5846 - mean_absolute_error: 10.2130 - mean_squared_error: 201.5846 - val_loss: 193.7227 - val_mean_absolute_error: 10.3755 - val_mean_squared_error: 193.7227\n"
     ]
    }
   ],
   "source": [
    "trained_model,training = train_model(model, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42c640",
   "metadata": {},
   "source": [
    "Defening and measuring the model outputs according to test splits to measure how well the model is trained we are measuring the Mean Squared Error between predictions and the real outputs, Mean Absolute Error, Root of the MSE and lastly the R2 score to evaluate the overall quality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4397b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    print(\"Model evaluations:\\n\")\n",
    "    print(f\"Mean Squared Error: {mse}\\n\")\n",
    "    print(f\"Mean Absolute Error: {mae}\\n\")\n",
    "    print(f\"R2 Score: {r2}\\n\")\n",
    "    print(f\"Root Mean Squared Error: {rmse}\\n\")\n",
    "    \n",
    "    return mse,mae,r2,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65a40440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5860/5860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step\n",
      "Model evaluations:\n",
      "\n",
      "Mean Squared Error: 197.32586705354754\n",
      "\n",
      "Mean Absolute Error: 10.626487284851073\n",
      "\n",
      "R2 Score: 0.9491136793202063\n",
      "\n",
      "Root Mean Squared Error: 14.047272584154816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d459e3",
   "metadata": {},
   "source": [
    "Above results indicate a very well output score of %94.9 R2 score this means model explains the calorie expenditure with %95 of variance its a very good score for the first and raw traning we have done, RMSE is 14.05 this indicates model predicts calories larger than the true expenditure and lastly MAE is 10.62 directly indicates the absolute difference avg between prediction to truth. \n",
    "Now lets try to upgrade this model to a more advanced version for reducing the error scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2e404",
   "metadata": {},
   "source": [
    "**Feature Engineering**\n",
    "On the above cells we use the data as given we did not create any meaninful columns combining what we have on the data we can populate the columns with what data we have examples:\n",
    "\n",
    "***1.BMI(weight/height^2)***\n",
    "Measures a persons Body Mass Index indicates if a personis underweight, normal, overweight or obese. This measurement can give us a deeper understanding for calorie predictions.\n",
    "\n",
    "***2.Calorie Rate(calorie/duration)***\n",
    "Colorie expenditure per duration.\n",
    "\n",
    "***3.Temp adjusted heart rate***\n",
    "High body temp can increase hearth rate this can indicate more calorie expenditure than nromal parameters normalizing this to 37 degrees can give us reduced calori exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650e18e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_with_features(dataframe):\n",
    "    if dataframe.isna().sum().sum() > 0 or dataframe.isnull().sum().sum() > 0:\n",
    "        dataframe.dropna\n",
    "    \n",
    "    dataframe['BMI'] = dataframe['Weight'] / ((dataframe['Height']/100) ** 2)\n",
    "    dataframe['Calorie_Rate'] = dataframe['Calories'] / dataframe['Duration']\n",
    "    dataframe['Adjusted_HR'] = dataframe['Heart_Rate'] * (37/dataframe['Body_Temp'])\n",
    "    \n",
    "    X = dataframe.drop(columns='Calories')\n",
    "    Y = dataframe['Calories']\n",
    "    \n",
    "    numeric_features = ['Age','Height','Weight','Heart_Rate','Body_Temp','BMI','Calorie_Rate','Adjusted_HR']\n",
    "    categorical_features = ['Sex']\n",
    "    \n",
    "    num_encoder = StandardScaler()\n",
    "    cat_encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers= [('num', num_encoder, numeric_features),('cat',cat_encoder,categorical_features)])\n",
    "    \n",
    "    X_precessed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_precessed, Y , test_size=0.25, random_state=42)\n",
    "    \n",
    "    print(f\"X_train_enh shape: {X_train.shape}\")\n",
    "    print(f\"X_test_enh shape: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe79f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_enh shape: (562500, 9)\n",
      "X_test_enh shape: (187500, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train_enh, X_test_enh, Y_train_enh, Y_test_enh = process_data_with_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ec8f8",
   "metadata": {},
   "source": [
    "***Enhance Model Architecture***\n",
    "Compiling a more deep layered Neural Network with deeper layers and with different loss function to increase prediction accuracy. This enhanced model uses Huber loss function that combines MSE and MAE loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfdd5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_model_building(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(96, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                  loss= keras.losses.Huber(delta=1.0), \n",
    "                  metrics=[keras.metrics.MeanSquaredError(name=\"mean_squared_error\", dtype=None), \n",
    "                  keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None)\n",
    "                  ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_model = advanced_model_building(X_train_enh.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7fc6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_enhanced_model(model, x_train, x_test, y_train, y_test):\n",
    "    callbacks = [keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    'best_param_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,    \n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patiance=5,\n",
    "    min_lr=1e-6,\n",
    "    )]\n",
    "    \n",
    "    traning = model.fit(x= x_train,\n",
    "              y=y_train,\n",
    "              epochs= 150,\n",
    "              callbacks=[callbacks],\n",
    "              batch_size=32,\n",
    "              validation_data=(x_test, y_test),\n",
    "              verbose=1\n",
    "              )\n",
    "    \n",
    "    return best_model, traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa4b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m17577/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.2944 - mean_absolute_error: 17.7833 - mean_squared_error: 1058.5295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 14ms/step - loss: 17.2934 - mean_absolute_error: 17.7823 - mean_squared_error: 1058.4164 - val_loss: 8.6411 - val_mean_absolute_error: 9.1213 - val_mean_squared_error: 199.5453 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 13ms/step - loss: 9.6030 - mean_absolute_error: 10.0875 - mean_squared_error: 203.7120 - val_loss: 9.0777 - val_mean_absolute_error: 9.5587 - val_mean_squared_error: 193.2251 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 14ms/step - loss: 9.3795 - mean_absolute_error: 9.8629 - mean_squared_error: 195.3717 - val_loss: 8.9882 - val_mean_absolute_error: 9.4680 - val_mean_squared_error: 193.9948 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 14ms/step - loss: 9.2521 - mean_absolute_error: 9.7352 - mean_squared_error: 191.1024 - val_loss: 8.9307 - val_mean_absolute_error: 9.4117 - val_mean_squared_error: 201.0615 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 14ms/step - loss: 9.2034 - mean_absolute_error: 9.6861 - mean_squared_error: 189.3438 - val_loss: 8.6828 - val_mean_absolute_error: 9.1647 - val_mean_squared_error: 179.2965 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 13ms/step - loss: 9.1332 - mean_absolute_error: 9.6158 - mean_squared_error: 187.1295 - val_loss: 8.7296 - val_mean_absolute_error: 9.2104 - val_mean_squared_error: 207.2230 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m17577/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.1024 - mean_absolute_error: 9.5851 - mean_squared_error: 186.1299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 13ms/step - loss: 9.1024 - mean_absolute_error: 9.5851 - mean_squared_error: 186.1299 - val_loss: 8.5658 - val_mean_absolute_error: 9.0474 - val_mean_squared_error: 191.7610 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 13ms/step - loss: 9.0556 - mean_absolute_error: 9.5382 - mean_squared_error: 184.0773 - val_loss: 8.7339 - val_mean_absolute_error: 9.2153 - val_mean_squared_error: 192.1521 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 13ms/step - loss: 9.0334 - mean_absolute_error: 9.5157 - mean_squared_error: 183.3579 - val_loss: 8.7134 - val_mean_absolute_error: 9.1950 - val_mean_squared_error: 187.0565 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 13ms/step - loss: 9.0401 - mean_absolute_error: 9.5224 - mean_squared_error: 184.3229 - val_loss: 8.6933 - val_mean_absolute_error: 9.1738 - val_mean_squared_error: 195.9092 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 13ms/step - loss: 9.0037 - mean_absolute_error: 9.4859 - mean_squared_error: 182.6577 - val_loss: 9.0507 - val_mean_absolute_error: 9.5317 - val_mean_squared_error: 186.2273 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 13ms/step - loss: 8.9908 - mean_absolute_error: 9.4727 - mean_squared_error: 182.0005 - val_loss: 8.7712 - val_mean_absolute_error: 9.2531 - val_mean_squared_error: 183.8103 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 14ms/step - loss: 8.9512 - mean_absolute_error: 9.4331 - mean_squared_error: 180.3704 - val_loss: 8.6239 - val_mean_absolute_error: 9.1032 - val_mean_squared_error: 179.2670 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m17577/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.9381 - mean_absolute_error: 9.4199 - mean_squared_error: 180.9547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 14ms/step - loss: 8.9381 - mean_absolute_error: 9.4199 - mean_squared_error: 180.9547 - val_loss: 8.5617 - val_mean_absolute_error: 9.0410 - val_mean_squared_error: 185.1270 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 15ms/step - loss: 8.9474 - mean_absolute_error: 9.4292 - mean_squared_error: 180.4247 - val_loss: 8.7259 - val_mean_absolute_error: 9.2055 - val_mean_squared_error: 176.0440 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m17579/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 15ms/step - loss: 8.9522 - mean_absolute_error: 9.4338 - mean_squared_error: 181.1817 - val_loss: 8.8641 - val_mean_absolute_error: 9.3449 - val_mean_squared_error: 184.2149 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m17577/17579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9272 - mean_absolute_error: 9.4092 - mean_squared_error: 180.0956"
     ]
    }
   ],
   "source": [
    "trained_enhanced_model, enhanced_model_traning = train_enhanced_model(enhanced_model, X_train_enh, X_test_enh, Y_train_enh, Y_test_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9fa937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traning_session(traning_history):\n",
    "    plt.Figure(figsize=(12,12))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(traning_history.history['loss'])\n",
    "    plt.plot(traning_history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341242e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
